{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r0WXVWYNKetf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "3833d62c-8860-492d-8ee6-9ff37807076a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Choose an option:\n",
            "1. Download data for a single company\n",
            "2. Download data for multiple companies (enter names)\n",
            "3. Upload Excel file with company names\n",
            "Enter your choice (1, 2, or 3): 1\n",
            "Enter company name to download data for: Tata Motors Ltd\n",
            "\n",
            "Processing Tata Motors Ltd...\n",
            "Fetching data from https://www.screener.in/company/TATAMOTORS/consolidated/\n",
            "Data saved to Tata_Motors_Ltd_data.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1c76ceae-6831-4470-80c6-de3b8c442e27\", \"Tata_Motors_Ltd_data.xlsx\", 12292)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File download initiated for Tata_Motors_Ltd_data.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install requests beautifulsoup4 pandas openpyxl\n",
        "\n",
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "from google.colab import files\n",
        "import getpass\n",
        "\n",
        "class ScreenerDownloader:\n",
        "    def __init__(self, username=None, password=None):\n",
        "        self.base_url = \"https://www.screener.in\"\n",
        "        self.session = requests.Session()\n",
        "        self.logged_in = False\n",
        "\n",
        "        # If credentials provided, login\n",
        "        if username and password:\n",
        "            self.login(username, password)\n",
        "\n",
        "    def login(self, username=None, password=None):\n",
        "        \"\"\"Log in to Screener.in\"\"\"\n",
        "        if not username:\n",
        "            username = input(\"Enter your Screener.in username/email: \")\n",
        "        if not password:\n",
        "            password = getpass.getpass(\"Enter your Screener.in password: \")\n",
        "\n",
        "        login_url = f\"{self.base_url}/login/\"\n",
        "\n",
        "        # First get the CSRF token\n",
        "        response = self.session.get(login_url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        csrf_token = soup.find('input', {'name': 'csrfmiddlewaretoken'}).get('value')\n",
        "\n",
        "        # Now login\n",
        "        login_data = {\n",
        "            'csrfmiddlewaretoken': csrf_token,\n",
        "            'username': username,\n",
        "            'password': password,\n",
        "            'next': '/'\n",
        "        }\n",
        "\n",
        "        headers = {\n",
        "            'Referer': login_url,\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        response = self.session.post(login_url, data=login_data, headers=headers)\n",
        "\n",
        "        # Check if login was successful\n",
        "        if \"Login - \" not in response.text:\n",
        "            print(\"Login successful!\")\n",
        "            self.logged_in = True\n",
        "        else:\n",
        "            print(\"Login failed. Please check your credentials.\")\n",
        "            self.logged_in = False\n",
        "\n",
        "    def search_company(self, company_name):\n",
        "        \"\"\"Search for a company and return its URL\"\"\"\n",
        "        search_url = f\"{self.base_url}/company/{company_name}/\"\n",
        "\n",
        "        # Try direct URL first (if company_name is actually a URL-friendly company name)\n",
        "        response = self.session.get(search_url)\n",
        "        if response.status_code == 200 and \"is not found\" not in response.text:\n",
        "            return search_url\n",
        "\n",
        "        # If direct URL doesn't work, try search\n",
        "        search_url = f\"{self.base_url}/api/company/search/?q={company_name}\"\n",
        "        response = self.session.get(search_url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            results = response.json()\n",
        "            if results and len(results) > 0:\n",
        "                # Get the first result\n",
        "                company_url = results[0].get('url')\n",
        "                if company_url:\n",
        "                    return f\"{self.base_url}{company_url}\"\n",
        "\n",
        "        print(f\"Company '{company_name}' not found.\")\n",
        "        return None\n",
        "\n",
        "    def get_company_data(self, company_url):\n",
        "        \"\"\"Extract financial data from company page\"\"\"\n",
        "        print(f\"Fetching data from {company_url}\")\n",
        "        response = self.session.get(company_url)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to fetch data: {response.status_code}\")\n",
        "            return None\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Get company name\n",
        "        company_name_elem = soup.find('h1')\n",
        "        if company_name_elem:\n",
        "            company_name = company_name_elem.text.strip()\n",
        "        else:\n",
        "            # Fallback if h1 is not found\n",
        "            title = soup.find('title')\n",
        "            company_name = title.text.strip() if title else \"Unknown Company\"\n",
        "\n",
        "        # Get all tables on the page\n",
        "        data = {}\n",
        "        tables = soup.find_all('table')\n",
        "\n",
        "        for table in tables:\n",
        "            # Try to find the table title in a nearby h2 or h3\n",
        "            table_title = None\n",
        "            element = table.find_previous(['h2', 'h3', 'h4'])\n",
        "            if element:\n",
        "                table_title = element.text.strip()\n",
        "            else:\n",
        "                # If no specific title found, use \"Table X\"\n",
        "                table_title = f\"Table {len(data) + 1}\"\n",
        "\n",
        "            # Get table data\n",
        "            table_data = self._extract_table_data(table)\n",
        "            if table_data is not None:\n",
        "                data[table_title] = table_data\n",
        "\n",
        "        # Get ratios and metrics from the page\n",
        "        ratios = {}\n",
        "\n",
        "        # Try different selectors as the website might have changed\n",
        "        ratio_elements = soup.select('div.flex-row span.flex-1') or soup.select('.financial-ratios .data-card')\n",
        "\n",
        "        for element in ratio_elements:\n",
        "            try:\n",
        "                # Try different class names for label and value\n",
        "                label_elem = element.find('span', class_='name') or element.find('span', class_='flex-1') or element.find('div', class_='name')\n",
        "                value_elem = element.find('span', class_='number') or element.find('span', class_='font-medium') or element.find('div', class_='value')\n",
        "\n",
        "                if label_elem and value_elem:\n",
        "                    label = label_elem.text.strip()\n",
        "                    value = value_elem.text.strip()\n",
        "                    ratios[label] = value\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting ratio: {e}\")\n",
        "                continue\n",
        "\n",
        "        data['Key Ratios'] = ratios\n",
        "\n",
        "        # Get company basic info - try multiple selector patterns as site may have changed\n",
        "        company_info = {}\n",
        "\n",
        "        # Try different selectors for company info sections\n",
        "        info_sections = soup.select('div.company-ratios > div.flex.flex-wrap') or soup.select('.company-info .flex.flex-wrap')\n",
        "\n",
        "        if info_sections:\n",
        "            for section in info_sections:\n",
        "                # Try different class patterns for labels and values\n",
        "                labels = section.select('span.font-normal') or section.select('.label')\n",
        "                values = section.select('span.font-semibold') or section.select('.value')\n",
        "\n",
        "                for i in range(min(len(labels), len(values))):\n",
        "                    label = labels[i].text.strip()\n",
        "                    value = values[i].text.strip()\n",
        "                    company_info[label] = value\n",
        "        else:\n",
        "            # Alternative method - look for key-value pairs\n",
        "            info_rows = soup.select('.company-ratios li') or soup.select('.company-info li')\n",
        "            for row in info_rows:\n",
        "                try:\n",
        "                    text = row.get_text(strip=True)\n",
        "                    if ':' in text:\n",
        "                        label, value = text.split(':', 1)\n",
        "                        company_info[label.strip()] = value.strip()\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        data['Company Info'] = company_info\n",
        "\n",
        "        return {'company_name': company_name, 'data': data}\n",
        "\n",
        "    def _extract_table_data(self, table):\n",
        "        \"\"\"Extract data from a table into a pandas DataFrame\"\"\"\n",
        "        rows = table.find_all('tr')\n",
        "        if not rows:\n",
        "            return None\n",
        "\n",
        "        # Get all headers\n",
        "        headers = []\n",
        "        header_row = rows[0]\n",
        "        for th in header_row.find_all(['th', 'td']):\n",
        "            headers.append(th.text.strip())\n",
        "\n",
        "        # Get all data rows\n",
        "        data = []\n",
        "        for row in rows[1:]:\n",
        "            cols = row.find_all(['th', 'td'])\n",
        "            row_data = []\n",
        "            for col in cols:\n",
        "                row_data.append(col.text.strip())\n",
        "            data.append(row_data)\n",
        "\n",
        "        # Handle empty data\n",
        "        if not data:\n",
        "            return pd.DataFrame(columns=headers)\n",
        "\n",
        "        # Ensure all rows have the same length as headers\n",
        "        max_cols = max(len(row) for row in data)\n",
        "        header_count = len(headers)\n",
        "\n",
        "        # Adjust headers if needed\n",
        "        if max_cols > header_count:\n",
        "            headers.extend([f'Column {i+1}' for i in range(header_count, max_cols)])\n",
        "\n",
        "        # Create DataFrame with the right number of columns\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Ensure we have the right number of column names\n",
        "        column_names = headers[:len(df.columns)]\n",
        "        if len(column_names) < len(df.columns):\n",
        "            column_names.extend([f'Column {i+1}' for i in range(len(column_names), len(df.columns))])\n",
        "\n",
        "        df.columns = column_names\n",
        "        return df\n",
        "\n",
        "    def save_data(self, data, output_file=None):\n",
        "        \"\"\"Save company data to Excel file\"\"\"\n",
        "        if not data:\n",
        "            print(\"No data to save.\")\n",
        "            return\n",
        "\n",
        "        company_name = data['company_name']\n",
        "\n",
        "        # Clean company name for use in filename\n",
        "        clean_name = re.sub(r'[^\\w\\s-]', '', company_name).strip().replace(' ', '_')\n",
        "\n",
        "        if not output_file:\n",
        "            output_file = f\"{clean_name}_data.xlsx\"\n",
        "\n",
        "        with pd.ExcelWriter(output_file) as writer:\n",
        "            # Create a summary sheet\n",
        "            summary = pd.DataFrame(list(data['data'].get('Key Ratios', {}).items()),\n",
        "                                   columns=['Ratio', 'Value'])\n",
        "            summary.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "            # Create a company info sheet\n",
        "            company_info = pd.DataFrame(list(data['data'].get('Company Info', {}).items()),\n",
        "                                      columns=['Info', 'Value'])\n",
        "            company_info.to_excel(writer, sheet_name='Company Info', index=False)\n",
        "\n",
        "            # Add other data tables\n",
        "            for table_name, table_data in data['data'].items():\n",
        "                if table_name in ['Key Ratios', 'Company Info']:\n",
        "                    continue\n",
        "\n",
        "                if isinstance(table_data, pd.DataFrame):\n",
        "                    # Truncate sheet name if too long for Excel\n",
        "                    sheet_name = table_name[:31] if len(table_name) > 31 else table_name\n",
        "                    table_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        print(f\"Data saved to {output_file}\")\n",
        "        # For Colab: Download the file automatically\n",
        "        try:\n",
        "            files.download(output_file)\n",
        "            print(f\"File download initiated for {output_file}\")\n",
        "        except:\n",
        "            print(f\"Please download the file manually from the Colab file browser\")\n",
        "        return output_file\n",
        "\n",
        "    def download_company_data(self, company_name, output_file=None):\n",
        "        \"\"\"Complete workflow to download and save company data\"\"\"\n",
        "        company_url = self.search_company(company_name)\n",
        "        if not company_url:\n",
        "            return None\n",
        "\n",
        "        company_data = self.get_company_data(company_url)\n",
        "        if not company_data:\n",
        "            return None\n",
        "\n",
        "        output_file = self.save_data(company_data, output_file)\n",
        "        return output_file\n",
        "\n",
        "# Define a more robust function to handle errors gracefully\n",
        "def safe_download_company(downloader, company_name):\n",
        "    try:\n",
        "        print(f\"\\nProcessing {company_name}...\")\n",
        "        return downloader.download_company_data(company_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {company_name}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def download_from_excel(downloader, excel_file):\n",
        "    \"\"\"Download data for companies listed in an Excel file\"\"\"\n",
        "    print(f\"Reading company names from: {excel_file}\")\n",
        "    try:\n",
        "        # Read the Excel file\n",
        "        df = pd.read_excel(excel_file)\n",
        "\n",
        "        # Look for a column with company names\n",
        "        company_col = None\n",
        "        possible_column_names = ['company', 'company name', 'name', 'companies', 'stock']\n",
        "\n",
        "        # Find the first column that matches our expected naming patterns\n",
        "        for col in df.columns:\n",
        "            if col.lower() in possible_column_names or any(name in col.lower() for name in possible_column_names):\n",
        "                company_col = col\n",
        "                break\n",
        "\n",
        "        # If we can't find a likely column, use the first column\n",
        "        if company_col is None:\n",
        "            company_col = df.columns[0]\n",
        "            print(f\"Using first column '{company_col}' for company names\")\n",
        "        else:\n",
        "            print(f\"Using column '{company_col}' for company names\")\n",
        "\n",
        "        # Extract the company names\n",
        "        companies = df[company_col].dropna().tolist()\n",
        "        print(f\"Found {len(companies)} companies to process\")\n",
        "\n",
        "        # Create a new directory for all downloads\n",
        "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "        output_dir = f\"screener_data_{timestamp}\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        print(f\"Created output directory: {output_dir}\")\n",
        "\n",
        "        # Download data for each company\n",
        "        successful = 0\n",
        "        failed = 0\n",
        "        for i, company in enumerate(companies):\n",
        "            print(f\"\\nProcessing company {i+1}/{len(companies)}: {company}\")\n",
        "            output_file = os.path.join(output_dir, f\"{company.replace(' ', '_')}_data.xlsx\")\n",
        "\n",
        "            try:\n",
        "                result = downloader.download_company_data(company, output_file)\n",
        "                if result:\n",
        "                    successful += 1\n",
        "                else:\n",
        "                    failed += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {str(e)}\")\n",
        "                failed += 1\n",
        "\n",
        "            # Add a delay to avoid overloading the server\n",
        "            time.sleep(2)\n",
        "\n",
        "        print(f\"\\nProcessing complete. Successful: {successful}, Failed: {failed}\")\n",
        "\n",
        "        # Create a zip file of all results\n",
        "        zip_filename = f\"{output_dir}.zip\"\n",
        "        print(f\"Creating zip file: {zip_filename}\")\n",
        "\n",
        "        # Use system commands to create a zip file\n",
        "        !zip -r {zip_filename} {output_dir}\n",
        "\n",
        "        # Download the zip file\n",
        "        try:\n",
        "            files.download(zip_filename)\n",
        "            print(f\"Download initiated for {zip_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not auto-download zip file: {str(e)}\")\n",
        "            print(f\"Please download {zip_filename} manually from the Colab file browser\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing Excel file: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Example usage - Run this section to download data\n",
        "try:\n",
        "    # Create the downloader\n",
        "    downloader = ScreenerDownloader()\n",
        "\n",
        "    # Optional: Log in for premium features\n",
        "    # Uncomment the line below if you want to log in\n",
        "    # downloader.login()\n",
        "\n",
        "    # Choose download mode\n",
        "    print(\"Choose an option:\")\n",
        "    print(\"1. Download data for a single company\")\n",
        "    print(\"2. Download data for multiple companies (enter names)\")\n",
        "    print(\"3. Upload Excel file with company names\")\n",
        "\n",
        "    choice = input(\"Enter your choice (1, 2, or 3): \")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # Download single company\n",
        "        company_name = input(\"Enter company name to download data for: \")\n",
        "        safe_download_company(downloader, company_name)\n",
        "    elif choice == \"2\":\n",
        "        # Download multiple companies\n",
        "        companies = input(\"Enter company names separated by commas: \").split(',')\n",
        "        for company in companies:\n",
        "            company = company.strip()\n",
        "            if company:\n",
        "                safe_download_company(downloader, company)\n",
        "                # Add a small delay between requests\n",
        "                time.sleep(2)\n",
        "    elif choice == \"3\":\n",
        "        print(\"Please upload an Excel file with company names:\")\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if uploaded:\n",
        "            # Get the filename of the uploaded file\n",
        "            excel_file = list(uploaded.keys())[0]\n",
        "            download_from_excel(downloader, excel_file)\n",
        "        else:\n",
        "            print(\"No file was uploaded.\")\n",
        "    else:\n",
        "        print(\"Invalid choice. Please run again and select 1, 2, or 3.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    print(\"Please try again or check if Screener.in website structure has changed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xArA7iSVkZsd"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}